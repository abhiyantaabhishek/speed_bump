{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhiyantaabhishek/speed_bump/blob/master/yolo_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3ccY8eqMb7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62133e18-4370-4868-d7f3-359b949b4d0e"
      },
      "source": [
        "!git clone https://github.com/abhiyantaabhishek/keras-yolo3\n",
        "%cd keras-yolo3/\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-yolo3'...\n",
            "remote: Enumerating objects: 220, done.\u001b[K\n",
            "Receiving objects:   0% (1/220)   \rReceiving objects:   1% (3/220)   \rReceiving objects:   2% (5/220)   \rReceiving objects:   3% (7/220)   \rReceiving objects:   4% (9/220)   \rReceiving objects:   5% (11/220)   \rReceiving objects:   6% (14/220)   \rReceiving objects:   7% (16/220)   \rReceiving objects:   8% (18/220)   \rReceiving objects:   9% (20/220)   \rReceiving objects:  10% (22/220)   \rReceiving objects:  11% (25/220)   \rReceiving objects:  12% (27/220)   \rReceiving objects:  13% (29/220)   \rReceiving objects:  14% (31/220)   \rReceiving objects:  15% (33/220)   \rReceiving objects:  16% (36/220)   \rReceiving objects:  17% (38/220)   \rReceiving objects:  18% (40/220)   \rReceiving objects:  19% (42/220)   \rReceiving objects:  20% (44/220)   \rReceiving objects:  21% (47/220)   \rReceiving objects:  22% (49/220)   \rReceiving objects:  23% (51/220)   \rReceiving objects:  24% (53/220)   \rReceiving objects:  25% (55/220)   \rReceiving objects:  26% (58/220)   \rReceiving objects:  27% (60/220)   \rReceiving objects:  28% (62/220)   \rReceiving objects:  29% (64/220)   \rReceiving objects:  30% (66/220)   \rReceiving objects:  31% (69/220)   \rReceiving objects:  32% (71/220)   \rremote: Total 220 (delta 0), reused 0 (delta 0), pack-reused 220\u001b[K\n",
            "Receiving objects:  33% (73/220)   \rReceiving objects:  34% (75/220)   \rReceiving objects:  35% (77/220)   \rReceiving objects:  36% (80/220)   \rReceiving objects:  37% (82/220)   \rReceiving objects:  38% (84/220)   \rReceiving objects:  39% (86/220)   \rReceiving objects:  40% (88/220)   \rReceiving objects:  41% (91/220)   \rReceiving objects:  42% (93/220)   \rReceiving objects:  43% (95/220)   \rReceiving objects:  44% (97/220)   \rReceiving objects:  45% (99/220)   \rReceiving objects:  46% (102/220)   \rReceiving objects:  47% (104/220)   \rReceiving objects:  48% (106/220)   \rReceiving objects:  49% (108/220)   \rReceiving objects:  50% (110/220)   \rReceiving objects:  51% (113/220)   \rReceiving objects:  52% (115/220)   \rReceiving objects:  53% (117/220)   \rReceiving objects:  54% (119/220)   \rReceiving objects:  55% (121/220)   \rReceiving objects:  56% (124/220)   \rReceiving objects:  57% (126/220)   \rReceiving objects:  58% (128/220)   \rReceiving objects:  59% (130/220)   \rReceiving objects:  60% (132/220)   \rReceiving objects:  61% (135/220)   \rReceiving objects:  62% (137/220)   \rReceiving objects:  63% (139/220)   \rReceiving objects:  64% (141/220)   \rReceiving objects:  65% (143/220)   \rReceiving objects:  66% (146/220)   \rReceiving objects:  67% (148/220)   \rReceiving objects:  68% (150/220)   \rReceiving objects:  69% (152/220)   \rReceiving objects:  70% (154/220)   \rReceiving objects:  71% (157/220)   \rReceiving objects:  72% (159/220)   \rReceiving objects:  73% (161/220)   \rReceiving objects:  74% (163/220)   \rReceiving objects:  75% (165/220)   \rReceiving objects:  76% (168/220)   \rReceiving objects:  77% (170/220)   \rReceiving objects:  78% (172/220)   \rReceiving objects:  79% (174/220)   \rReceiving objects:  80% (176/220)   \rReceiving objects:  81% (179/220)   \rReceiving objects:  82% (181/220)   \rReceiving objects:  83% (183/220)   \rReceiving objects:  84% (185/220)   \rReceiving objects:  85% (187/220)   \rReceiving objects:  86% (190/220)   \rReceiving objects:  87% (192/220)   \rReceiving objects:  88% (194/220)   \rReceiving objects:  89% (196/220)   \rReceiving objects:  90% (198/220)   \rReceiving objects:  91% (201/220)   \rReceiving objects:  92% (203/220)   \rReceiving objects:  93% (205/220)   \rReceiving objects:  94% (207/220)   \rReceiving objects:  95% (209/220)   \rReceiving objects:  96% (212/220)   \rReceiving objects:  97% (214/220)   \rReceiving objects:  98% (216/220)   \rReceiving objects:  99% (218/220)   \rReceiving objects: 100% (220/220)   \rReceiving objects: 100% (220/220), 91.27 KiB | 6.52 MiB/s, done.\n",
            "Resolving deltas:   0% (0/118)   \rResolving deltas:   1% (2/118)   \rResolving deltas:   6% (8/118)   \rResolving deltas:   9% (11/118)   \rResolving deltas:  11% (13/118)   \rResolving deltas:  12% (15/118)   \rResolving deltas:  15% (18/118)   \rResolving deltas:  16% (19/118)   \rResolving deltas:  19% (23/118)   \rResolving deltas:  21% (25/118)   \rResolving deltas:  22% (26/118)   \rResolving deltas:  33% (40/118)   \rResolving deltas:  35% (42/118)   \rResolving deltas:  36% (43/118)   \rResolving deltas:  42% (50/118)   \rResolving deltas:  49% (58/118)   \rResolving deltas:  52% (62/118)   \rResolving deltas:  53% (63/118)   \rResolving deltas:  55% (66/118)   \rResolving deltas:  60% (71/118)   \rResolving deltas:  63% (75/118)   \rResolving deltas:  64% (76/118)   \rResolving deltas:  67% (80/118)   \rResolving deltas:  68% (81/118)   \rResolving deltas:  75% (89/118)   \rResolving deltas:  87% (103/118)   \rResolving deltas:  88% (105/118)   \rResolving deltas:  94% (111/118)   \rResolving deltas:  96% (114/118)   \rResolving deltas:  97% (115/118)   \rResolving deltas: 100% (118/118)   \rResolving deltas: 100% (118/118), done.\n",
            "/content/keras-yolo3\n",
            "Requirement already satisfied: absl-py==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.2.2)\n",
            "Requirement already satisfied: google-pasta==0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.1.8)\n",
            "Collecting grpcio==1.26.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/8f/f79c5c174bebece41f824dd7b1ba98da45dc2d4c373b38ac6a7f6a5acb5e/grpcio-1.26.0-cp36-cp36m-manylinux2010_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 4.9MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 40.0MB/s \n",
            "\u001b[?25hCollecting Keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 64.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.0.8)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.0)\n",
            "Collecting Markdown==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 14.8MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 159kB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python==4.1.2.30 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (4.1.2.30)\n",
            "Requirement already satisfied: opt-einsum==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (3.1.0)\n",
            "Collecting protobuf==3.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ac/838c8c8a5f33a58132dd2ad2a30329f6ae1614a9f56ffb79eaaf71a9d156/protobuf-3.11.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 52.4MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 73.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (1.4.1)\n",
            "Collecting six==1.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorboard==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (1.15.0)\n",
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (1.15.1)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 21)) (1.1.0)\n",
            "Collecting tqdm==4.41.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c9/7fc20feac72e79032a7c8138fd0d395dc6d8812b5b9edf53c3afd0b31017/tqdm-4.41.1-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 11.0MB/s \n",
            "\u001b[?25hCollecting Werkzeug==0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt==1.11.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 24)) (1.11.2)\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.6/dist-packages (from Markdown==3.1.1->-r requirements.txt (line 10)) (45.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r requirements.txt (line 18)) (0.34.2)\n",
            "Building wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3-cp36-cp36m-linux_x86_64.whl size=44229 sha256=61ac9ca1667482db0e34c9debc9a3df54d7305b00e6c7d8a8d28d235d5c879ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
            "Successfully built PyYAML\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, grpcio, numpy, h5py, PyYAML, Keras, Markdown, protobuf, tqdm, Werkzeug\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: grpcio 1.27.1\n",
            "    Uninstalling grpcio-1.27.1:\n",
            "      Successfully uninstalled grpcio-1.27.1\n",
            "  Found existing installation: numpy 1.17.5\n",
            "    Uninstalling numpy-1.17.5:\n",
            "      Successfully uninstalled numpy-1.17.5\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "  Found existing installation: Markdown 3.2.1\n",
            "    Uninstalling Markdown-3.2.1:\n",
            "      Successfully uninstalled Markdown-3.2.1\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "  Found existing installation: Werkzeug 1.0.0\n",
            "    Uninstalling Werkzeug-1.0.0:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9881dM63MkSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights -O yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ_Uh1UnNoZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "\n",
        "file_id = '1-51KP0sL0dbc9hTcRyzax52xLWg49YSw'\n",
        "destination = 'yolov3.weights'\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZGteXGvMlhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model\n",
        "import struct\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70JVcy1vMwnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stp8arAvM0cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major,    = struct.unpack('i', w_f.read(4))\n",
        "            minor,    = struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "\n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "            \n",
        "            binary = w_f.read()\n",
        "\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "        \n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\n",
        "                print(\"loading weights of convolution #\" + str(i))\n",
        "\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
        "\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance            \n",
        "\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n",
        "\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    \n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                print(\"no convolution #\" + str(i))     \n",
        "    \n",
        "    def reset(self):\n",
        "        self.offset = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtJYVc1xM3nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        \n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "            \n",
        "        return self.score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TrAUyIgM6O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    \n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "        \n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "        x = Conv2D(conv['filter'], \n",
        "                   conv['kernel'], \n",
        "                   strides=conv['stride'], \n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']), \n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\n",
        "    return add([skip_connection, x]) if skip else x\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3          \n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    \n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    return float(intersect) / union\n",
        "\n",
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "\n",
        "    # Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "    # Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "    # Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "    # Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "        \n",
        "    skip_36 = x\n",
        "        \n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "        \n",
        "    skip_61 = x\n",
        "        \n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "        \n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\n",
        "    # Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    # Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\n",
        "    # Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
        "    return model\n",
        "\n",
        "def preprocess_input(image, net_h, net_w):\n",
        "    new_h, new_w, _ = image.shape\n",
        "\n",
        "    # determine the new size of the image\n",
        "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
        "        new_h = (new_h * net_w)/new_w\n",
        "        new_w = net_w\n",
        "    else:\n",
        "        new_w = (new_w * net_h)/new_h\n",
        "        new_h = net_h\n",
        "\n",
        "    # resize the image to the new size\n",
        "    resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n",
        "\n",
        "    # embed the image into the standard letter box\n",
        "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
        "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
        "    new_image = np.expand_dims(new_image, 0)\n",
        "\n",
        "    return new_image\n",
        "\n",
        "def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "\n",
        "    boxes = []\n",
        "\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        \n",
        "        for b in range(nb_box):\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            #objectness = netout[..., :4]\n",
        "            \n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "            \n",
        "            # first 4 elements are x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n",
        "            \n",
        "            # last elements are class probabilities\n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "            \n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "            boxes.append(box)\n",
        "\n",
        "    return boxes\n",
        "\n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "        \n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "        \n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        "        \n",
        "def do_nms(boxes, nms_thresh):\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "        \n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0\n",
        "                    \n",
        "def draw_boxes(image, boxes, labels, obj_thresh):\n",
        "    for box in boxes:\n",
        "        label_str = ''\n",
        "        label = -1\n",
        "        \n",
        "        for i in range(len(labels)):\n",
        "            if box.classes[i] > obj_thresh:\n",
        "                label_str += labels[i]\n",
        "                label = i\n",
        "                print(labels[i] + ': ' + str(box.classes[i]*100) + '%')\n",
        "                \n",
        "        if label >= 0:\n",
        "            cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (0,255,0), 3)\n",
        "            cv2.putText(image, \n",
        "                        label_str + ' ' + str(box.get_score()), \n",
        "                        (box.xmin, box.ymin - 13), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                        1e-3 * image.shape[0], \n",
        "                        (0,255,0), 2)\n",
        "        \n",
        "    return image      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq3sb57pM9iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/keras-yolo3/yolov3.weights' \n",
        "image_path   = '/content/drive/My Drive/bump_dataset/ir_det_dataset/ir_det_dataset/Images/rgb/006269.png'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nz3KCPlNAkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set some parameters\n",
        "net_h, net_w = 416, 416\n",
        "obj_thresh, nms_thresh = 0.5, 0.45\n",
        "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
        "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
        "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
        "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
        "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
        "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
        "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
        "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
        "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
        "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "# make the yolov3 model to predict 80 classes on COCO\n",
        "yolov3 = make_yolov3_model()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDaX3GXTNFlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the weights trained on COCO into the model\n",
        "weight_reader = WeightReader(weights_path)\n",
        "weight_reader.load_weights(yolov3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlgqkjCSNIeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#image_path   = '/content/drive/My Drive/bump_dataset/ir_det_dataset/ir_det_dataset/Images/rgb/007519.png'\n",
        "image_path   = '/content/drive/My Drive/bump_dataset/ir_det_dataset/ir_det_dataset/Images/rgb/007495.png'\n",
        "# preprocess the image\n",
        "image = cv2.imread(image_path)\n",
        "image_h, image_w, _ = image.shape\n",
        "new_image = preprocess_input(image, net_h, net_w)\n",
        "\n",
        "# run the prediction\n",
        "yolos = yolov3.predict(new_image)\n",
        "boxes = []\n",
        "\n",
        "for i in range(len(yolos)):\n",
        "    # decode the output of the network\n",
        "    boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\n",
        "\n",
        "# correct the sizes of the bounding boxes\n",
        "correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
        "\n",
        "# suppress non-maximal boxes\n",
        "do_nms(boxes, nms_thresh)     \n",
        "\n",
        "# draw bounding boxes on the image using labels\n",
        "draw_boxes(image, boxes, labels, obj_thresh) \n",
        "plt.imshow(image)\n",
        "# write the image with bounding boxes to file\n",
        "#cv2.imwrite(image_path[:-4] + '_detected' + image_path[-4:], (image).astype('uint8')) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}